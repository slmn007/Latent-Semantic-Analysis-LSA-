{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Crawling Data From Web PTA.Trunojoyo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk melakukan Crawling disini diperlukan sebuah Library python bernama Scrapy<br>\n",
    "\"pip install Scrapy\"<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "class Url(scrapy.Spider):\n",
    "    name = \"url\"\n",
    "    start_urls = []\n",
    "    \n",
    "    def __init__(self):\n",
    "        url = 'https://pta.trunojoyo.ac.id/c_search/byprod/10/'\n",
    "        for page in range(1,13):\n",
    "            self.start_urls.append(url + str(page))\n",
    "        \n",
    "    def parse(self, response):\n",
    "        for page in range(1,6):\n",
    "            for url in response.css('#content_journal > ul'):\n",
    "                yield {\n",
    "                    'url' : url.css('li:nth-child('+str(page)+') > div:nth-child(3) > a ::attr(href)').extract()\n",
    "                } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "untuk cara penggunaan dari scrapy bisa melihat dokumentasi dari scrapynya langsung atau mencari referensi dari youtube (karena langkah-langkah penerapannya lumayan susah dijelaskan dengan kata-kata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "script diatas dijalankan kedalam file bereksistensi \".py\" lalu menjalankan perintah berikut di CMD atau terminal ditempat file ini berada\n",
    "\"scrapy runspider -nama file.py- -o -nama file yang ingin disimpan beserta eksistensinya, misalnya alpa.json-\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Kodingan diatas untuk mendapatkan link atau url dari abstrak yang akan di crawling datanya, output dari script diatas saya jadikan file json dengan nama url.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import json\n",
    "\n",
    "class Pta(scrapy.Spider):\n",
    "    name = \"pta\"\n",
    "    file_json = open(\"url.json\")\n",
    "    start_urls = json.loads(file_json.read())\n",
    "    urls = []\n",
    "\n",
    "    for i in range(len(start_urls)):\n",
    "        b = start_urls[i]['url'][0]\n",
    "        urls.append(b)\n",
    "    \n",
    "    def start_requests(self):\n",
    "        for url in self.urls:\n",
    "            yield scrapy.Request(url = url, callback = self.parse)\n",
    "        \n",
    "    def parse(self, response):\n",
    "        # print(response.url)\n",
    "\n",
    "        for jurnal in response.css('#content_journal > ul > li'):\n",
    "            yield {\n",
    "                'Judul':jurnal.css('div:nth-child(2) > a::text').get(),\n",
    "                'Penulis':jurnal.css('div:nth-child(2) > div:nth-child(2) > span::text').get()[10:],\n",
    "                'Dosbing_1':jurnal.css('div:nth-child(2) > div:nth-child(3) > span::text').get()[21:],\n",
    "                'Dosbing_2':jurnal.css('div:nth-child(2) > div:nth-child(4) > span::text').get()[22:],\n",
    "                'Abstrak_indo':jurnal.css('div:nth-child(4) > div:nth-child(2) > p::text').get(),\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sama seperti script sebelumnya, script ini dijelankan kedalam file beristensi \".py\" dan hasilnya bisa di simpan dengan perintah di terminal sama seperti yang sebelumnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">hasil dari running script ini saya jadikan file csv dengan nama jurnal.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1b15f5df67a702be8f228f6d0b6061fe0c39795279c81537b9d6008feba9a7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
